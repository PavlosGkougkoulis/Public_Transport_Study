# -*- coding: utf-8 -*-
"""Data_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oPLOeAcP0NLLYhYoe9akFUCEgZIZVHz0

# **1. Correlation Matrices and Means**

## 1. KTEL

### **1.1 KTEL - Correlation Matrix**
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from tabulate import tabulate
import numpy as np


# Read Excel file into DataFrame
df = pd.read_excel('KTEL.xlsx')

# Drop 'N_PARTICIPANT' column
df = df.drop(columns=['N_PARTICIPANT'])

# Calculate correlation matrix
corr_matrix = df.corr()

# Set up the matplotlib figure
plt.figure(figsize=(20, 20))

# Generate a custom diverging colormap
cmap = sns.diverging_palette(220, 20, as_cmap=True)

# Draw the heatmap with the mask and correct aspect ratio
sns.heatmap(corr_matrix, cmap=cmap, vmax=1, vmin=-1, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5},
            annot=False)

# Show plot
plt.title('Correlation Matrix - KTEL')
plt.show()

"""### **1.2 KTEL - Means**"""

# Read Excel files into DataFrames
df_ktel = pd.read_excel('KTEL.xlsx')

# Drop 'N_PARTICIPANT' column for the KTEL DataFrame
df_ktel = df_ktel.drop(columns=['N_PARTICIPANT'])

# Calculate means for each variable in KTEL DataFrame
means_ktel = df_ktel.mean().round(2)

# Convert means to a DataFrame
means_df_ktel = pd.DataFrame({'Variable': means_ktel.index, 'Mean': means_ktel.values})

# Plot the table
fig, ax = plt.subplots(figsize=(8, 6))
ax.axis('tight')
ax.axis('off')

# Create the table
table = ax.table(cellText=means_df_ktel.values,
                 colLabels=means_df_ktel.columns,
                 cellLoc='center',
                 loc='center')  # Set the table location to center

# Set table properties
table.auto_set_font_size(False)
table.set_fontsize(10)
table.scale(1.2, 1.2)  # Scale up the table for better readability

plt.savefig('means_ktel.jpg', bbox_inches='tight', pad_inches=0.5)
plt.show()

"""##2. OSE

### **2.1 OSE - Correlation Matrix**
"""

# Read Excel file into DataFrame
df = pd.read_excel('OSE.xlsx')

# Drop 'N_PARTICIPANT' column
df = df.drop(columns=['N_PARTICIPANT'])

# Calculate correlation matrix
corr_matrix = df.corr()

# Set up the matplotlib figure
plt.figure(figsize=(20, 20))

# Generate a custom diverging colormap
cmap = sns.diverging_palette(220, 20, as_cmap=True)

# Draw the heatmap with the mask and correct aspect ratio
sns.heatmap(corr_matrix, cmap=cmap, vmax=1, vmin=-1, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5},
            annot=False)

# Show plot
plt.title('Correlation Matrix - OSE')
plt.show()

"""### **2.2 OSE - Means**"""

# Read Excel files into DataFrames
df_ose = pd.read_excel('OSE.xlsx')

# Drop 'N_PARTICIPANT' column for the OSE DataFrame
df_ose = df_ose.drop(columns=['N_PARTICIPANT'])

# Calculate means for each variable in OSE DataFrame
means_ose = df_ose.mean().round(2)

# Convert means to a DataFrame
means_df_ose = pd.DataFrame({'Variable': means_ose.index, 'Mean': means_ose.values})

# Plot the table
fig, ax = plt.subplots(figsize=(8, 6))
ax.axis('tight')
ax.axis('off')

# Create the table
table = ax.table(cellText=means_df_ose.values,
                 colLabels=means_df_ose.columns,
                 cellLoc='center',
                 loc='center')  # Set the table location to center

# Set table properties
table.auto_set_font_size(False)
table.set_fontsize(10)
table.scale(1.2, 1.2)  # Scale up the table for better readability

plt.savefig('means_ose.jpg', bbox_inches='tight', pad_inches=0.5)
plt.show()

"""##3. LIMANI

### **3.1 LIMANI - Correlation Matrix**
"""

# Read Excel file into DataFrame
df = pd.read_excel('LIMANI.xlsx')

# Drop 'N_PARTICIPANT' column
df = df.drop(columns=['N_PARTICIPANT'])

# Calculate correlation matrix
corr_matrix = df.corr()

# Set up the matplotlib figure
plt.figure(figsize=(20, 20))

# Generate a custom diverging colormap
cmap = sns.diverging_palette(220, 20, as_cmap=True)

# Draw the heatmap with the mask and correct aspect ratio
sns.heatmap(corr_matrix, cmap=cmap, vmax=1, vmin=-1, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5},
            annot=False)

# Show plot
plt.title('Correlation Matrix - LIMANI')
plt.show()

"""### **3.2 LIMANI - Means**"""

# Read Excel files into DataFrames
df_limani = pd.read_excel('LIMANI.xlsx')

# Drop 'N_PARTICIPANT' column for the LIMANI DataFrame
df_limani = df_limani.drop(columns=['N_PARTICIPANT'])

# Calculate means for each variable in LIMANI DataFrame
means_limani = df_limani.mean().round(2)

# Convert means to a DataFrame
means_df_limani = pd.DataFrame({'Variable': means_limani.index, 'Mean': means_limani.values})

# Plot the table
fig, ax = plt.subplots(figsize=(8, 6))
ax.axis('tight')
ax.axis('off')

# Create the table
table = ax.table(cellText=means_df_limani.values,
                 colLabels=means_df_limani.columns,
                 cellLoc='center',
                 loc='center')  # Set the table location to center

# Set table properties
table.auto_set_font_size(False)
table.set_fontsize(10)
table.scale(1.2, 1.2)  # Scale up the table for better readability

plt.savefig('means_limani.jpg', bbox_inches='tight', pad_inches=0.5)
plt.show()

"""# **2. Grouping, Cronbach Alpha Values, Tables and Means**

## 1. KTEL
"""

# Load the dataset from the Excel file
data = pd.read_excel('KTEL.xlsx')

# Remove the N_PARTICIPANT column
data = data.drop(columns=['N_PARTICIPANT'])

# Define the groups correctly
groups = {
    "TIME": ["TIME_WAITED", "ACCURACY", "BOARDING_TIME"],
    "PASSENGERS": ["AVAIL_SEATS", "PERSON_SPACE", "COPASS_BEHAVIOUR", "TRAVEL_PERSONS", "WHEELCHAIR", "BABY_STROLLER", "KIDS", "LUGGAGE", "AGED", "VISION_HELP", "BIKE_FOLD", "DOG", "OTHER", "DISABILITY"],
    "INFORMATION": ["INFO_OUT", "INFO_IN", "HELP_DRIVER", "PRODUCT_INFO", "INFO_TRIP"],
    "SAFETY": ["PERSON_SAFETY", "DRIVING_SAFETY", "PERSONNAL_SAFETY"],
    "STATION": ["CLEANLINESS_OUT", "ENTRANCE_OPT", "CLEANLINESS_INS", "TICKET_SELL", "BUILDING_MAINT", "STATION_CLEAN", "FACILITY_STATION", "STAFF_STATION", "STAFF_HELP", "PUBLIC_TRANSP_CONN", "PARKING_CARS", "PARKING_BIKES", "ENV_STATION", "ROOF_STATION", "SEATS_STATION", "CATER_FAC_STATION", "TICKET_PRICE_SATISFACTION"],
    "TRIP_TRANSPORT": ["AVAIL_SEATS", "SEAT_COMFORT", "TEMP_INS", "CONTRACTOR_DRIVER", "SEAT_RESERV", "TRANSPORT_CARD", "MULT_TRANS_OFFER", "TRANS_PURPOSE", "TRANSP_FREQ", "REASON_TRANSP_MEANS", "TRIP_SATISFACTION"],
    "CHARACTERISTICS": ["GENDER", "DRIVING_LIC", "PRIVATE_CAR_USE", "TWOWH_USE", "BIKE_USE", "NONE_ABOVE", "AGE", "EDUCATION_LVL", "JOB", "PPL_IN_HOUSE", "FAMILY_INCOME"]
}

# Ensure all relevant columns are numeric and handle missing values
for group, columns in groups.items():
    for col in columns:
        if col in data.columns:
            data[col] = pd.to_numeric(data[col], errors='coerce')  # Convert to numeric and coerce errors to NaN
        else:
            data[col] = np.nan  # Create columns with NaN if they don't exist in the data

# Function to calculate Cronbach's Alpha
def cronbach_alpha(df):
    df = df.dropna(axis=1, how='any')  # Drop columns with NaN values
    if df.shape[1] < 2:  # Need at least two items to calculate alpha
        return np.nan
    itemscores = df.values
    itemvars = itemscores.var(axis=0, ddof=1)
    tscores = itemscores.sum(axis=1)
    nitems = len(df.columns)
    return nitems / (nitems - 1) * (1 - itemvars.sum() / tscores.var(ddof=1))

# Calculate Cronbach's alpha for each group
cronbach_alphas = {group: cronbach_alpha(data[columns].dropna()) for group, columns in groups.items()}

# Calculate means for each group
group_means = {group: data[columns].mean(axis=1).mean() for group, columns in groups.items()}

# Printing and Visualization
# Grouping information and Cronbach's alpha
group_info = [{"Group": group, "Variables": ", ".join(columns), "Cronbach Alpha": alpha}
              for group, columns, alpha in zip(groups.keys(), groups.values(), cronbach_alphas.values())]

# Convert group_info to a DataFrame for better visualization
group_info_df = pd.DataFrame(group_info)

# Means of each group
means_info = [{"Group": group, "Mean": mean} for group, mean in group_means.items()]
means_info_df = pd.DataFrame(means_info)

# Plotting Cronbach's Alphas
plt.figure(figsize=(12, 6))
sns.barplot(x=list(cronbach_alphas.keys()), y=list(cronbach_alphas.values()))
plt.title("Cronbach's Alpha for Each Group - KTEL")
plt.xlabel('Group')
plt.ylabel("Cronbach's Alpha")
plt.xticks(rotation=90)  # Rotate x-axis labels vertically
for index, value in enumerate(cronbach_alphas.values()):
    if np.isfinite(value):
        plt.text(index, value, f'{value:.2f}', ha='center', va='bottom')
plt.tight_layout()
plt.savefig('cronbach_alphas.png')
plt.show()

# Convert group_means values to a list of floats
group_means_values = [value for value in group_means.values()]

# Plotting Group Means
plt.figure(figsize=(12, 6))
sns.barplot(x=list(group_means.keys()), y=group_means_values)
plt.title('Mean Values for Each Group - KTEL')
plt.xlabel('Group')
plt.ylabel('Mean Value')
plt.xticks(rotation=90)  # Rotate x-axis labels vertically
for index, value in enumerate(group_means_values):
    plt.text(index, value, f'{value:.2f}', ha='center', va='bottom')
plt.tight_layout()
plt.savefig('group_means.png')
plt.show()

print("Grouping Information and Cronbach's Alpha:")
print(tabulate(group_info, headers="keys", tablefmt="fancy_grid"))

print("\nMeans of Each Group:")
print(tabulate(means_info, headers="keys", tablefmt="fancy_grid"))

print("\nCronbach Alphas:")
for group, alpha in cronbach_alphas.items():
    print(f"{group}: {alpha}")

print("\nGroup Means:")
for group, mean in group_means.items():
    print(f"{group}: {mean}")

# Plot correlation matrices for each group
correlation_matrices = {group: data[columns].corr() for group, columns in groups.items()}

for group, correlation_matrix in correlation_matrices.items():
    plt.figure(figsize=(10, 8))
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", annot_kws={"ha": 'center', "va": 'center'})
    plt.title(f'Correlation Matrix - {group} (KTEL)')
    plt.xlabel('Variables')
    plt.ylabel('Variables')
    plt.xticks(rotation=90)  # Rotate x-tick labels vertically
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.savefig(f'correlation_matrix_{group}.png')
    plt.show()

# Function to calculate mean values for each group
def calculate_group_means(data, groups):
    group_means = {}
    for group, columns in groups.items():
        group_means[group] = data[columns].mean(axis=1)
    return group_means

# Calculate mean values for each group
group_means = calculate_group_means(data, groups)

# Convert group means into a DataFrame
group_means_df = pd.DataFrame(group_means)

# Calculate correlation matrix for group means
group_correlation_matrix = group_means_df.corr()

# Plot correlation matrix for groups
plt.figure(figsize=(10, 8))
sns.heatmap(group_correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix - Groups (KTEL)')
plt.xlabel('Groups')
plt.ylabel('Groups')
plt.xticks(rotation=90)  # Rotate x-axis labels vertically
plt.yticks(rotation=0)
plt.tight_layout()
plt.savefig('group_correlation_matrix.png')
plt.show()

"""## 2. OSE"""

# Load the dataset from the Excel file
data = pd.read_excel('OSE.xlsx')

# Remove the N_PARTICIPANT column
data = data.drop(columns=['N_PARTICIPANT'])

# Define the groups correctly
groups = {
    "TIME": ["TIME_WAITED", "ACCURACY", "BOARDING_TIME"],
    "PASSENGERS": ["AVAIL_SEATS", "PERSON_SPACE", "COPASS_BEHAVIOUR", "TRAVEL_PERSONS", "WHEELCHAIR", "BABY_STROLLER", "KIDS", "LUGGAGE", "AGED", "VISION_HELP", "BIKE_FOLD", "DOG", "OTHER", "DISABILITY"],
    "INFORMATION": ["INFO_OUT", "INFO_IN", "HELP_DRIVER", "PRODUCT_INFO", "INFO_TRIP"],
    "SAFETY": ["PERSON_SAFETY", "DRIVING_SAFETY", "PERSONNAL_SAFETY"],
    "STATION": ["CLEANLINESS_OUT", "ENTRANCE_OPT", "CLEANLINESS_INS", "TICKET_SELL", "BUILDING_MAINT", "STATION_CLEAN", "FACILITY_STATION", "STAFF_STATION", "STAFF_HELP", "PUBLIC_TRANSP_CONN", "PARKING_CARS", "PARKING_BIKES", "ENV_STATION", "ROOF_STATION", "SEATS_STATION", "CATER_FAC_STATION", "TICKET_PRICE_SATISFACTION"],
    "TRIP_TRANSPORT": ["AVAIL_SEATS", "SEAT_COMFORT", "TEMP_INS", "CONTRACTOR_DRIVER", "SEAT_RESERV", "TRANSPORT_CARD", "MULT_TRANS_OFFER", "TRANS_PURPOSE", "TRANSP_FREQ", "REASON_TRANSP_MEANS", "TRIP_SATISFACTION"],
    "CHARACTERISTICS": ["GENDER", "DRIVING_LIC", "PRIVATE_CAR_USE", "TWOWH_USE", "BIKE_USE", "NONE_ABOVE", "AGE", "EDUCATION_LVL", "JOB", "PPL_IN_HOUSE", "FAMILY_INCOME"]
}

# Ensure all relevant columns are numeric and handle missing values
for group, columns in groups.items():
    for col in columns:
        if col in data.columns:
            data[col] = pd.to_numeric(data[col], errors='coerce')  # Convert to numeric and coerce errors to NaN
        else:
            data[col] = np.nan  # Create columns with NaN if they don't exist in the data

# Function to calculate Cronbach's Alpha
def cronbach_alpha(df):
    df = df.dropna(axis=1, how='any')  # Drop columns with NaN values
    if df.shape[1] < 2:  # Need at least two items to calculate alpha
        return np.nan
    itemscores = df.values
    itemvars = itemscores.var(axis=0, ddof=1)
    tscores = itemscores.sum(axis=1)
    nitems = len(df.columns)
    return nitems / (nitems - 1) * (1 - itemvars.sum() / tscores.var(ddof=1))

# Calculate Cronbach's alpha for each group
cronbach_alphas = {group: cronbach_alpha(data[columns].dropna()) for group, columns in groups.items()}

# Calculate means for each group
group_means = {group: data[columns].mean(axis=1).mean() for group, columns in groups.items()}

# Printing and Visualization
# Grouping information and Cronbach's alpha
group_info = [{"Group": group, "Variables": ", ".join(columns), "Cronbach Alpha": alpha}
              for group, columns, alpha in zip(groups.keys(), groups.values(), cronbach_alphas.values())]

# Convert group_info to a DataFrame for better visualization
group_info_df = pd.DataFrame(group_info)

# Means of each group
means_info = [{"Group": group, "Mean": mean} for group, mean in group_means.items()]
means_info_df = pd.DataFrame(means_info)

# Plotting Cronbach's Alphas
plt.figure(figsize=(12, 6))
sns.barplot(x=list(cronbach_alphas.keys()), y=list(cronbach_alphas.values()))
plt.title("Cronbach's Alpha for Each Group - OSE")
plt.xlabel('Group')
plt.ylabel("Cronbach's Alpha")
plt.xticks(rotation=90)  # Rotate x-axis labels vertically
for index, value in enumerate(cronbach_alphas.values()):
    if np.isfinite(value):
        plt.text(index, value, f'{value:.2f}', ha='center', va='bottom')
plt.tight_layout()
plt.savefig('cronbach_alphas.png')
plt.show()

# Convert group_means values to a list of floats
group_means_values = [value for value in group_means.values()]

# Plotting Group Means
plt.figure(figsize=(12, 6))
sns.barplot(x=list(group_means.keys()), y=group_means_values)
plt.title('Mean Values for Each Group - OSE')
plt.xlabel('Group')
plt.ylabel('Mean Value')
plt.xticks(rotation=90)  # Rotate x-axis labels vertically
for index, value in enumerate(group_means_values):
    plt.text(index, value, f'{value:.2f}', ha='center', va='bottom')
plt.tight_layout()
plt.savefig('group_means.png')
plt.show()

print("Grouping Information and Cronbach's Alpha:")
print(tabulate(group_info, headers="keys", tablefmt="fancy_grid"))

print("\nMeans of Each Group:")
print(tabulate(means_info, headers="keys", tablefmt="fancy_grid"))

print("\nCronbach Alphas:")
for group, alpha in cronbach_alphas.items():
    print(f"{group}: {alpha}")

print("\nGroup Means:")
for group, mean in group_means.items():
    print(f"{group}: {mean}")

# Plot correlation matrices for each group
correlation_matrices = {group: data[columns].corr() for group, columns in groups.items()}

for group, correlation_matrix in correlation_matrices.items():
    plt.figure(figsize=(10, 8))
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", annot_kws={"ha": 'center', "va": 'center'})
    plt.title(f'Correlation Matrix - {group} (OSE)')
    plt.xlabel('Variables')
    plt.ylabel('Variables')
    plt.xticks(rotation=90)  # Rotate x-tick labels vertically
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.savefig(f'correlation_matrix_{group}.png')
    plt.show()

# Function to calculate mean values for each group
def calculate_group_means(data, groups):
    group_means = {}
    for group, columns in groups.items():
        group_means[group] = data[columns].mean(axis=1)
    return group_means

# Calculate mean values for each group
group_means = calculate_group_means(data, groups)

# Convert group means into a DataFrame
group_means_df = pd.DataFrame(group_means)

# Calculate correlation matrix for group means
group_correlation_matrix = group_means_df.corr()

# Plot correlation matrix for groups
plt.figure(figsize=(10, 8))
sns.heatmap(group_correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix - Groups (OSE)')
plt.xlabel('Groups')
plt.ylabel('Groups')
plt.xticks(rotation=90)  # Rotate x-axis labels vertically
plt.yticks(rotation=0)
plt.tight_layout()
plt.savefig('group_correlation_matrix.png')
plt.show()

"""## 3. LIMANI"""

# Load the dataset from the Excel file
data = pd.read_excel('LIMANI.xlsx')

# Remove the N_PARTICIPANT column
data = data.drop(columns=['N_PARTICIPANT'])

# Define the groups correctly
groups = {
    "TIME": ["TIME_WAITED", "ACCURACY", "BOARDING_TIME"],
    "PASSENGERS": ["AVAIL_SEATS", "PERSON_SPACE", "COPASS_BEHAVIOUR", "TRAVEL_PERSONS", "WHEELCHAIR", "BABY_STROLLER", "KIDS", "LUGGAGE", "AGED", "VISION_HELP", "BIKE_FOLD", "DOG", "OTHER", "DISABILITY"],
    "INFORMATION": ["INFO_OUT", "INFO_IN", "HELP_DRIVER", "PRODUCT_INFO", "INFO_TRIP"],
    "SAFETY": ["PERSON_SAFETY", "DRIVING_SAFETY", "PERSONNAL_SAFETY"],
    "STATION": ["CLEANLINESS_OUT", "ENTRANCE_OPT", "CLEANLINESS_INS", "TICKET_SELL", "BUILDING_MAINT", "STATION_CLEAN", "FACILITY_STATION", "STAFF_STATION", "STAFF_HELP", "PUBLIC_TRANSP_CONN", "PARKING_CARS", "PARKING_BIKES", "ENV_STATION", "ROOF_STATION", "SEATS_STATION", "CATER_FAC_STATION", "TICKET_PRICE_SATISFACTION"],
    "TRIP_TRANSPORT": ["AVAIL_SEATS", "SEAT_COMFORT", "TEMP_INS", "CONTRACTOR_DRIVER", "SEAT_RESERV", "TRANSPORT_CARD", "MULT_TRANS_OFFER", "TRANS_PURPOSE", "TRANSP_FREQ", "REASON_TRANSP_MEANS", "TRIP_SATISFACTION"],
    "CHARACTERISTICS": ["GENDER", "DRIVING_LIC", "PRIVATE_CAR_USE", "TWOWH_USE", "BIKE_USE", "NONE_ABOVE", "AGE", "EDUCATION_LVL", "JOB", "PPL_IN_HOUSE", "FAMILY_INCOME"]
}

# Ensure all relevant columns are numeric and handle missing values
for group, columns in groups.items():
    for col in columns:
        if col in data.columns:
            data[col] = pd.to_numeric(data[col], errors='coerce')  # Convert to numeric and coerce errors to NaN
        else:
            data[col] = np.nan  # Create columns with NaN if they don't exist in the data

# Function to calculate Cronbach's Alpha
def cronbach_alpha(df):
    df = df.dropna(axis=1, how='any')  # Drop columns with NaN values
    if df.shape[1] < 2:  # Need at least two items to calculate alpha
        return np.nan
    itemscores = df.values
    itemvars = itemscores.var(axis=0, ddof=1)
    tscores = itemscores.sum(axis=1)
    nitems = len(df.columns)
    return nitems / (nitems - 1) * (1 - itemvars.sum() / tscores.var(ddof=1))

# Calculate Cronbach's alpha for each group
cronbach_alphas = {group: cronbach_alpha(data[columns].dropna()) for group, columns in groups.items()}

# Calculate means for each group
group_means = {group: data[columns].mean(axis=1).mean() for group, columns in groups.items()}

# Printing and Visualization
# Grouping information and Cronbach's alpha
group_info = [{"Group": group, "Variables": ", ".join(columns), "Cronbach Alpha": alpha}
              for group, columns, alpha in zip(groups.keys(), groups.values(), cronbach_alphas.values())]

# Convert group_info to a DataFrame for better visualization
group_info_df = pd.DataFrame(group_info)

# Means of each group
means_info = [{"Group": group, "Mean": mean} for group, mean in group_means.items()]
means_info_df = pd.DataFrame(means_info)

# Plotting Cronbach's Alphas
plt.figure(figsize=(12, 6))
sns.barplot(x=list(cronbach_alphas.keys()), y=list(cronbach_alphas.values()))
plt.title("Cronbach's Alpha for Each Group - LIMANI")
plt.xlabel('Group')
plt.ylabel("Cronbach's Alpha")
plt.xticks(rotation=90)  # Rotate x-axis labels vertically
for index, value in enumerate(cronbach_alphas.values()):
    if np.isfinite(value):
        plt.text(index, value, f'{value:.2f}', ha='center', va='bottom')
plt.tight_layout()
plt.savefig('cronbach_alphas.png')
plt.show()

# Convert group_means values to a list of floats
group_means_values = [value for value in group_means.values()]

# Plotting Group Means
plt.figure(figsize=(12, 6))
sns.barplot(x=list(group_means.keys()), y=group_means_values)
plt.title('Mean Values for Each Group - LIMANI')
plt.xlabel('Group')
plt.ylabel('Mean Value')
plt.xticks(rotation=90)  # Rotate x-axis labels vertically
for index, value in enumerate(group_means_values):
    plt.text(index, value, f'{value:.2f}', ha='center', va='bottom')
plt.tight_layout()
plt.savefig('group_means.png')
plt.show()

print("Grouping Information and Cronbach's Alpha:")
print(tabulate(group_info, headers="keys", tablefmt="fancy_grid"))

print("\nMeans of Each Group:")
print(tabulate(means_info, headers="keys", tablefmt="fancy_grid"))

print("\nCronbach Alphas:")
for group, alpha in cronbach_alphas.items():
    print(f"{group}: {alpha}")

print("\nGroup Means:")
for group, mean in group_means.items():
    print(f"{group}: {mean}")

# Plot correlation matrices for each group
correlation_matrices = {group: data[columns].corr() for group, columns in groups.items()}

for group, correlation_matrix in correlation_matrices.items():
    plt.figure(figsize=(10, 8))
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", annot_kws={"ha": 'center', "va": 'center'})
    plt.title(f'Correlation Matrix - {group} (LIMANI)')
    plt.xlabel('Variables')
    plt.ylabel('Variables')
    plt.xticks(rotation=90)  # Rotate x-tick labels vertically
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.savefig(f'correlation_matrix_{group}.png')
    plt.show()

# Function to calculate mean values for each group
def calculate_group_means(data, groups):
    group_means = {}
    for group, columns in groups.items():
        group_means[group] = data[columns].mean(axis=1)
    return group_means

# Calculate mean values for each group
group_means = calculate_group_means(data, groups)

# Convert group means into a DataFrame
group_means_df = pd.DataFrame(group_means)

# Calculate correlation matrix for group means
group_correlation_matrix = group_means_df.corr()

# Plot correlation matrix for groups
plt.figure(figsize=(10, 8))
sns.heatmap(group_correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix - Groups (LIMANI)')
plt.xlabel('Groups')
plt.ylabel('Groups')
plt.xticks(rotation=90)  # Rotate x-axis labels vertically
plt.yticks(rotation=0)
plt.tight_layout()
plt.savefig('group_correlation_matrix.png')
plt.show()

"""## Combinational Search Algorithm (KTEL Dataset Test)"""

import pandas as pd
import matplotlib.pyplot as plt

# Define the combinational search algorithm groups
combinational_groups = {
    "Group 1": ['BABY_STROLLER', 'BIKE_NON_FOLD', 'DOG', 'DISABILITY', 'PRIVATE_CAR_USE', 'BIKE_USE'],
    "Group 2": ['SEAT_COMFORT', 'PERSON_SPACE', 'WHEELCHAIR', 'SEATS_STATION'],
    "Group 3": ['INFO_OUT', 'INFO_IN', 'INFO_TRIP', 'BUILDING_MAINT', 'STAFF_STATION', 'CATER_FAC_STATION'],
    "Group 4": ['TIME_WAITED', 'ACCURACY', 'ENTRANCE_OPT', 'CLEANLINESS_INS', 'PERSON_SAFETY', 'DRIVING_SAFETY'],
    "Group 5": ['BOARDING_TIME', 'AVAIL_SEATS', 'TEMP_INS', 'CONTRACTOR_DRIVER', 'COPASS_BEHAVIOUR', 'ROOF_STATION'],
    "Group 6": ['VISION_HELP', 'OTHER'],
    "Group 7": ['TRANSPORT_CARD', 'MULT_TRANS_OFFER'],
    "Group 8": ['STATION_CLEAN', 'FACILITY_STATION', 'PARKING_BIKES', 'PERSONNAL_SAFETY', 'ENV_STATION', 'TICKET_PRICE_SATISFACTION'],
    "Group 9": ['AGE', 'JOB'],
    "Group 10": ['CLEANLINESS_OUT', 'PRODUCT_INFO', 'PUBLIC_TRANSP_CONN', 'REASON_TRANSP_MEANS', 'GENDER', 'PPL_IN_HOUSE'],
    "Group 11": ['TRANS_PURPOSE', 'TRAVEL_PERSONS', 'TRANSP_FREQ', 'TICKET_SELL', 'STAFF_HELP'],
    "Group 12": ['SEAT_RESERV', 'TRIP_SATISFACTION', 'DRIVING_LIC'],
    "Group 13": ['HELP_DRIVER', 'PARKING_CARS'],
    "Group 14": ['EDUCATION_LVL', 'FAMILY_INCOME'],
    "Group 15": ['KIDS', 'BIKE_FOLD'],
    "Group 16": ['LUGGAGE', 'TWOWH_USE'],
    "Group 17": ['AGED', 'NONE_ABOVE'],
}

# Define the predefined groups
predefined_groups = {
    "TIME": ["TIME_WAITED", "ACCURACY", "BOARDING_TIME"],
    "PASSENGERS": ["AVAIL_SEATS", "PERSON_SPACE", "COPASS_BEHAVIOUR", "TRAVEL_PERSONS", "WHEELCHAIR", "BABY_STROLLER", "KIDS", "LUGGAGE", "AGED", "VISION_HELP", "BIKE_FOLD", "DOG", "OTHER", "DISABILITY"],
    "INFORMATION": ["INFO_OUT", "INFO_IN", "HELP_DRIVER", "PRODUCT_INFO", "INFO_TRIP"],
    "SAFETY": ["PERSON_SAFETY", "DRIVING_SAFETY", "PERSONNAL_SAFETY"],
    "STATION": ["CLEANLINESS_OUT", "ENTRANCE_OPT", "CLEANLINESS_INS", "TICKET_SELL", "BUILDING_MAINT", "STATION_CLEAN", "FACILITY_STATION", "STAFF_STATION", "STAFF_HELP", "PUBLIC_TRANSP_CONN", "PARKING_CARS", "PARKING_BIKES", "ENV_STATION", "ROOF_STATION", "SEATS_STATION", "CATER_FAC_STATION", "TICKET_PRICE_SATISFACTION"],
    "TRIP_TRANSPORT": ["AVAIL_SEATS", "SEAT_COMFORT", "TEMP_INS", "CONTRACTOR_DRIVER", "SEAT_RESERV", "TRANSPORT_CARD", "MULT_TRANS_OFFER", "TRANS_PURPOSE", "TRANSP_FREQ", "REASON_TRANSP_MEANS", "TRIP_SATISFACTION"],
    "CHARACTERISTICS": ["GENDER", "DRIVING_LIC", "PRIVATE_CAR_USE", "TWOWH_USE", "BIKE_USE", "NONE_ABOVE", "AGE", "EDUCATION_LVL", "JOB", "PPL_IN_HOUSE", "FAMILY_INCOME"],
}

def plot_group_table(groups, title):
    # Calculate the maximum number of columns needed
    max_cols = max(len(members) for members in groups.values()) + 1

    # Calculate column widths based on the length of the longest variable name
    max_name_length = max(len(name) for members in groups.values() for name in members)
    col_widths = [0.1] + [0.9 / (max_cols - 1)] * (max_cols - 1)
    col_widths = [width * max_name_length / 15 for width in col_widths]  # Adjust column width dynamically

    fig, ax = plt.subplots(figsize=(18, len(groups) * 0.8))
    ax.axis('tight')
    ax.axis('off')

    # Prepare table data and ensure all rows have the same length
    table_data = [[group] + members + [''] * (max_cols - len(members) - 1) for group, members in groups.items()]

    table = plt.table(cellText=table_data, colLabels=["Group"] + [""] * (max_cols - 1), loc='center', cellLoc='center', colWidths=col_widths)
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1.5, 1.5)

    for (i, j), cell in table.get_celld().items():
        if i == 0:
            cell.set_text_props(weight='bold')
            cell.set_facecolor('#40466e')
            cell.set_text_props(color='w')
        else:
            cell.set_facecolor('#f5f5f5')

    plt.title(title, fontsize=16, weight='bold')
    plt.show()

# Plot combinational search algorithm groups
plot_group_table(combinational_groups, "Combinational Search Algorithm Groups")

# Plot predefined groups
plot_group_table(predefined_groups, "Predefined Groups")

"""### Cronbach Alpha Values"""

import matplotlib.pyplot as plt

# Define the groups and their Cronbach's alpha values
groups = [
    ('BABY_STROLLER', 'BIKE_NON_FOLD', 'DOG', 'DISABILITY', 'PRIVATE_CAR_USE', 'BIKE_USE'),
    ('SEAT_COMFORT', 'PERSON_SPACE', 'WHEELCHAIR', 'SEATS_STATION'),
    ('INFO_OUT', 'INFO_IN', 'INFO_TRIP', 'BUILDING_MAINT', 'STAFF_STATION', 'CATER_FAC_STATION'),
    ('TIME_WAITED', 'ACCURACY', 'ENTRANCE_OPT', 'CLEANLINESS_INS', 'PERSON_SAFETY', 'DRIVING_SAFETY'),
    ('BOARDING_TIME', 'AVAIL_SEATS', 'TEMP_INS', 'CONTRACTOR_DRIVER', 'COPASS_BEHAVIOUR', 'ROOF_STATION'),
    ('VISION_HELP', 'OTHER'),
    ('TRANSPORT_CARD', 'MULT_TRANS_OFFER'),
    ('STATION_CLEAN', 'FACILITY_STATION', 'PARKING_BIKES', 'PERSONNAL_SAFETY', 'ENV_STATION', 'TICKET_PRICE_SATISFACTION'),
    ('AGE', 'JOB'),
    ('CLEANLINESS_OUT', 'PRODUCT_INFO', 'PUBLIC_TRANSP_CONN', 'REASON_TRANSP_MEANS', 'GENDER', 'PPL_IN_HOUSE'),
    ('TRANS_PURPOSE', 'TRAVEL_PERSONS', 'TRANSP_FREQ', 'TICKET_SELL', 'STAFF_HELP'),
    ('SEAT_RESERV', 'TRIP_SATISFACTION', 'DRIVING_LIC'),
    ('HELP_DRIVER', 'PARKING_CARS'),
    ('EDUCATION_LVL', 'FAMILY_INCOME'),
    ('KIDS', 'BIKE_FOLD'),
    ('LUGGAGE', 'TWOWH_USE'),
    ('AGED', 'NONE_ABOVE')
]

alpha_values = [
    913.4685711555692,
    0.8914763068644846,
    0.8562589737394385,
    0.8216277920540721,
    0.7417820959574218,
    0.7259546898831003,
    0.6807795520556111,
    0.6692139113268638,
    0.5510532937282089,
    0.4827406454903779,
    0.4699408977623713,
    0.46799635861583944,
    0.43356564444636186,
    0.3592239256895101,
    -0.026315789473684206,
    -0.05356103339055372,
    -0.0858487879825426
]

# Adjusting the scale for readability
adjusted_alpha_values = [x if x < 10 else 10 for x in alpha_values]

# Plotting
plt.figure(figsize=(10, 6))
bars = plt.bar(range(1, len(groups)), adjusted_alpha_values[1:], color='skyblue')
plt.xticks(range(1, len(groups)), ['Group {}'.format(i+1) for i in range(1, len(groups))], rotation=90)
plt.ylabel("Cronbach's alpha")
plt.title("Cronbach's Alpha Values for Different Groups")

# Adding Cronbach alpha values on top of bars
for i, bar in enumerate(bars):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), '{:.2f}'.format(alpha_values[i+1]),
             ha='center', va='bottom')

# Adding text for Group 1
plt.text(0.5, 0.95, "Group 1: {:.2f}".format(alpha_values[0]), fontsize=10, transform=plt.gca().transAxes)

plt.tight_layout()
plt.show()

"""# **3. Statistics**

## **3.1 Descriptive Statistics**

### **3.1.1 KTEL**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Read the dataset
data = pd.read_excel('KTEL.xlsx')

# Remove 'N_PARTICIPANT' column
data = data.drop(columns=['N_PARTICIPANT'])

# Calculate descriptive statistics
statistics = data.describe()

# Transpose the statistics dataframe for better readability
statistics = statistics.transpose()

# Define the number of groups and variables per group
num_groups = 16
vars_per_group = 8

# Split the variables into groups
variable_groups = [statistics.iloc[i:i+vars_per_group] for i in range(0, len(statistics), vars_per_group)]

# Plot the statistics in multiple tables
for i, group in enumerate(variable_groups):
    # Plot the first part of each group
    fig, ax = plt.subplots(figsize=(12, 8))
    table = ax.table(cellText=group[['count', 'mean', 'std', 'mean']].round(2).values,
                     colLabels=['N', 'Mean', 'Std. Deviation', 'Mean'],
                     rowLabels=group.index,
                     loc='center', cellLoc='center')

    # Adjust row height
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 1.5)

    ax.set_title('Group {} - Part 1'.format(i+1))
    ax.axis('off')
    plt.show()

    # Plot the second part of each group
    fig, ax = plt.subplots(figsize=(12, 8))
    table = ax.table(cellText=group[['min', 'max', '25%', '75%']].round(2).values,
                     colLabels=['Minimum', 'Maximum', 'Lower Bound', 'Upper Bound'],
                     rowLabels=group.index,
                     loc='center', cellLoc='center')

    # Adjust row height
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 1.5)

    ax.set_title('Group {} - Part 2'.format(i+1))
    ax.axis('off')
    plt.show()

"""### **3.1.2 OSE**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Read the dataset
data = pd.read_excel('OSE.xlsx')

# Remove 'N_PARTICIPANT' column
data = data.drop(columns=['N_PARTICIPANT'])

# Calculate descriptive statistics
statistics = data.describe()

# Transpose the statistics dataframe for better readability
statistics = statistics.transpose()

# Define the number of groups and variables per group
num_groups = 16
vars_per_group = 8

# Split the variables into groups
variable_groups = [statistics.iloc[i:i+vars_per_group] for i in range(0, len(statistics), vars_per_group)]

# Plot the statistics in multiple tables
for i, group in enumerate(variable_groups):
    # Plot the first part of each group
    fig, ax = plt.subplots(figsize=(12, 8))
    table = ax.table(cellText=group[['count', 'mean', 'std', 'mean']].round(2).values,
                     colLabels=['N', 'Mean', 'Std. Deviation', 'Mean'],
                     rowLabels=group.index,
                     loc='center', cellLoc='center')

    # Adjust row height
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 1.5)

    ax.set_title('Group {} - Part 1'.format(i+1))
    ax.axis('off')
    plt.show()

    # Plot the second part of each group
    fig, ax = plt.subplots(figsize=(12, 8))
    table = ax.table(cellText=group[['min', 'max', '25%', '75%']].round(2).values,
                     colLabels=['Minimum', 'Maximum', 'Lower Bound', 'Upper Bound'],
                     rowLabels=group.index,
                     loc='center', cellLoc='center')

    # Adjust row height
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 1.5)

    ax.set_title('Group {} - Part 2'.format(i+1))
    ax.axis('off')
    plt.show()

"""### **3.1.3 LIMANI**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Read the dataset
data = pd.read_excel('LIMANI.xlsx')

# Remove 'N_PARTICIPANT' column
data = data.drop(columns=['N_PARTICIPANT'])

# Calculate descriptive statistics
statistics = data.describe()

# Transpose the statistics dataframe for better readability
statistics = statistics.transpose()

# Define the number of groups and variables per group
num_groups = 16
vars_per_group = 8

# Split the variables into groups
variable_groups = [statistics.iloc[i:i+vars_per_group] for i in range(0, len(statistics), vars_per_group)]

# Plot the statistics in multiple tables
for i, group in enumerate(variable_groups):
    # Plot the first part of each group
    fig, ax = plt.subplots(figsize=(12, 8))
    table = ax.table(cellText=group[['count', 'mean', 'std', 'mean']].round(2).values,
                     colLabels=['N', 'Mean', 'Std. Deviation', 'Mean'],
                     rowLabels=group.index,
                     loc='center', cellLoc='center')

    # Adjust row height
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 1.5)

    ax.set_title('Group {} - Part 1'.format(i+1))
    ax.axis('off')
    plt.show()

    # Plot the second part of each group
    fig, ax = plt.subplots(figsize=(12, 8))
    table = ax.table(cellText=group[['min', 'max', '25%', '75%']].round(2).values,
                     colLabels=['Minimum', 'Maximum', 'Lower Bound', 'Upper Bound'],
                     rowLabels=group.index,
                     loc='center', cellLoc='center')

    # Adjust row height
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 1.5)

    ax.set_title('Group {} - Part 2'.format(i+1))
    ax.axis('off')
    plt.show()

"""# **4. Overall Rating**

## 1. KTEL
"""

# Load the KTEL dataset from the Excel file
data_ktel = pd.read_excel('KTEL.xlsx')

# Define the groups correctly for the KTEL dataset
groups_ktel = {
    "TIME": ["TIME_WAITED", "ACCURACY", "BOARDING_TIME"],
    "PASSENGERS": ["AVAIL_SEATS", "PERSON_SPACE", "COPASS_BEHAVIOUR", "TRAVEL_PERSONS", "WHEELCHAIR", "BABY_STROLLER", "KIDS", "LUGGAGE", "AGED", "VISION_HELP", "BIKE_FOLD", "DOG", "OTHER", "DISABILITY"],
    "INFORMATION": ["INFO_OUT", "INFO_IN", "HELP_DRIVER", "PRODUCT_INFO", "INFO_TRIP"],
    "SAFETY": ["PERSON_SAFETY", "DRIVING_SAFETY", "PERSONNAL_SAFETY"],
    "STATION": ["CLEANLINESS_OUT", "ENTRANCE_OPT", "CLEANLINESS_INS", "TICKET_SELL", "BUILDING_MAINT", "STATION_CLEAN", "FACILITY_STATION", "STAFF_STATION", "STAFF_HELP", "PUBLIC_TRANSP_CONN", "PARKING_CARS", "PARKING_BIKES", "ENV_STATION", "ROOF_STATION", "SEATS_STATION", "CATER_FAC_STATION", "TICKET_PRICE_SATISFACTION"],
    "TRIP_TRANSPORT": ["AVAIL_SEATS", "SEAT_COMFORT", "TEMP_INS", "CONTRACTOR_DRIVER", "SEAT_RESERV", "TRANSPORT_CARD", "MULT_TRANS_OFFER", "TRANS_PURPOSE", "TRANSP_FREQ", "REASON_TRANSP_MEANS", "TRIP_SATISFACTION"],
    "CHARACTERISTICS": ["GENDER", "DRIVING_LIC", "PRIVATE_CAR_USE", "TWOWH_USE", "BIKE_USE", "NONE_ABOVE", "AGE", "EDUCATION_LVL", "JOB", "PPL_IN_HOUSE", "FAMILY_INCOME"]
}

# Calculate means for each group in the KTEL dataset
group_means_ktel = {group: data_ktel[columns].mean(axis=1).mean() for group, columns in groups_ktel.items()}

# Calculate the overall mean from the means of each group in the KTEL dataset
overall_mean_ktel = sum(group_means_ktel.values()) / len(group_means_ktel)

# Scale the overall mean from 0 to 5 for the KTEL dataset
scaled_mean_ktel = (overall_mean_ktel - min(group_means_ktel.values())) / (max(group_means_ktel.values()) - min(group_means_ktel.values())) * 5

# Round the values to two decimal places
overall_mean_ktel = round(overall_mean_ktel, 2)
scaled_mean_ktel = round(scaled_mean_ktel, 2)

# Calculate the scaled mean as a percentage for the KTEL dataset
scaled_mean_percentage_ktel = (scaled_mean_ktel / 5) * 100
scaled_mean_percentage_ktel = round(scaled_mean_percentage_ktel, 1)

print("Overall Mean for KTEL dataset:", overall_mean_ktel)
print("Scaled Mean (0-5) for KTEL dataset:", scaled_mean_ktel, "(Percentage:", scaled_mean_percentage_ktel, "%)")
print("Overall Evaluation of Transport Mean:", scaled_mean_percentage_ktel, "%")

"""## 2. OSE"""

# Load the OSE dataset from the Excel file
data_ose = pd.read_excel('OSE.xlsx')

# Define the groups correctly for the OSE dataset
groups_ose = {
    "TIME": ["TIME_WAITED", "ACCURACY", "BOARDING_TIME"],
    "PASSENGERS": ["AVAIL_SEATS", "PERSON_SPACE", "COPASS_BEHAVIOUR", "TRAVEL_PERSONS", "WHEELCHAIR", "BABY_STROLLER", "KIDS", "LUGGAGE", "AGED", "VISION_HELP", "BIKE_FOLD", "DOG", "OTHER", "DISABILITY"],
    "INFORMATION": ["INFO_OUT", "INFO_IN", "HELP_DRIVER", "PRODUCT_INFO", "INFO_TRIP"],
    "SAFETY": ["PERSON_SAFETY", "DRIVING_SAFETY", "PERSONNAL_SAFETY"],
    "STATION": ["CLEANLINESS_OUT", "ENTRANCE_OPT", "CLEANLINESS_INS", "TICKET_SELL", "BUILDING_MAINT", "STATION_CLEAN", "FACILITY_STATION", "STAFF_STATION", "STAFF_HELP", "PUBLIC_TRANSP_CONN", "PARKING_CARS", "PARKING_BIKES", "ENV_STATION", "ROOF_STATION", "SEATS_STATION", "CATER_FAC_STATION", "TICKET_PRICE_SATISFACTION"],
    "TRIP_TRANSPORT": ["AVAIL_SEATS", "SEAT_COMFORT", "TEMP_INS", "CONTRACTOR_DRIVER", "SEAT_RESERV", "TRANSPORT_CARD", "MULT_TRANS_OFFER", "TRANS_PURPOSE", "TRANSP_FREQ", "REASON_TRANSP_MEANS", "TRIP_SATISFACTION"],
    "CHARACTERISTICS": ["GENDER", "DRIVING_LIC", "PRIVATE_CAR_USE", "TWOWH_USE", "BIKE_USE", "NONE_ABOVE", "AGE", "EDUCATION_LVL", "JOB", "PPL_IN_HOUSE", "FAMILY_INCOME"]
}

# Calculate means for each group in the OSE dataset
group_means_ose = {group: data_ose[columns].mean(axis=1).mean() for group, columns in groups_ose.items()}

# Calculate the overall mean from the means of each group in the OSE dataset
overall_mean_ose = sum(group_means_ose.values()) / len(group_means_ose)

# Scale the overall mean from 0 to 5 for the OSE dataset
scaled_mean_ose = (overall_mean_ose - min(group_means_ose.values())) / (max(group_means_ose.values()) - min(group_means_ose.values())) * 5

# Round the values to two decimal places
overall_mean_ose = round(overall_mean_ose, 2)
scaled_mean_ose = round(scaled_mean_ose, 2)

# Calculate the scaled mean as a percentage for the OSE dataset
scaled_mean_percentage_ose = (scaled_mean_ose / 5) * 100
scaled_mean_percentage_ose = round(scaled_mean_percentage_ose, 1)

print("Overall Mean for OSE dataset:", overall_mean_ose)
print("Scaled Mean (0-5) for OSE dataset:", scaled_mean_ose, "(Percentage:", scaled_mean_percentage_ose, "%)")
print("Overall Evaluation of Transport Mean:", scaled_mean_percentage_ose, "%")

"""## 3. LIMANI"""

# Load the LIMANI dataset from the Excel file
data_limani = pd.read_excel('LIMANI.xlsx')

# Define the groups correctly for the LIMANI dataset
groups_limani = {
    "TIME": ["TIME_WAITED", "ACCURACY", "BOARDING_TIME"],
    "PASSENGERS": ["AVAIL_SEATS", "PERSON_SPACE", "COPASS_BEHAVIOUR", "TRAVEL_PERSONS", "WHEELCHAIR", "BABY_STROLLER", "KIDS", "LUGGAGE", "AGED", "VISION_HELP", "BIKE_FOLD", "DOG", "OTHER", "DISABILITY"],
    "INFORMATION": ["INFO_OUT", "INFO_IN", "HELP_DRIVER", "PRODUCT_INFO", "INFO_TRIP"],
    "SAFETY": ["PERSON_SAFETY", "DRIVING_SAFETY", "PERSONNAL_SAFETY"],
    "STATION": ["CLEANLINESS_OUT", "ENTRANCE_OPT", "CLEANLINESS_INS", "TICKET_SELL", "BUILDING_MAINT", "STATION_CLEAN", "FACILITY_STATION", "STAFF_STATION", "STAFF_HELP", "PUBLIC_TRANSP_CONN", "PARKING_CARS", "PARKING_BIKES", "ENV_STATION", "ROOF_STATION", "SEATS_STATION", "CATER_FAC_STATION", "TICKET_PRICE_SATISFACTION"],
    "TRIP_TRANSPORT": ["AVAIL_SEATS", "SEAT_COMFORT", "TEMP_INS", "CONTRACTOR_DRIVER", "SEAT_RESERV", "TRANSPORT_CARD", "MULT_TRANS_OFFER", "TRANS_PURPOSE", "TRANSP_FREQ", "REASON_TRANSP_MEANS", "TRIP_SATISFACTION"],
    "CHARACTERISTICS": ["GENDER", "DRIVING_LIC", "PRIVATE_CAR_USE", "TWOWH_USE", "BIKE_USE", "NONE_ABOVE", "AGE", "EDUCATION_LVL", "JOB", "PPL_IN_HOUSE", "FAMILY_INCOME"]
}

# Filter out columns that do not exist in the dataset
groups_limani_filtered = {group: [col for col in columns if col in data_limani.columns] for group, columns in groups_limani.items()}

# Calculate means for each group in the LIMANI dataset
group_means_limani = {group: data_limani[columns].mean(axis=1).mean() for group, columns in groups_limani_filtered.items()}

# Calculate the overall mean from the means of each group in the LIMANI dataset
overall_mean_limani = sum(group_means_limani.values()) / len(group_means_limani)

# Scale the overall mean from 0 to 5 for the LIMANI dataset
scaled_mean_limani = (overall_mean_limani - min(group_means_limani.values())) / (max(group_means_limani.values()) - min(group_means_limani.values())) * 5

# Round the values to two decimal places
overall_mean_limani = round(overall_mean_limani, 2)
scaled_mean_limani = round(scaled_mean_limani, 2)

# Calculate the scaled mean as a percentage for the LIMANI dataset
scaled_mean_percentage_limani = (scaled_mean_limani / 5) * 100
scaled_mean_percentage_limani = round(scaled_mean_percentage_limani, 1)

print("Overall Mean for LIMANI dataset:", overall_mean_limani)
print("Scaled Mean (0-5) for LIMANI dataset:", scaled_mean_limani, "(Percentage:", scaled_mean_percentage_limani,  "%)")
print("Overall Evaluation of Transport Mean:", scaled_mean_percentage_limani, "%")

"""## 4. Visualisation"""

# Data
datasets = ['KTEL', 'OSE', 'LIMANI']
overall_means = [2.83, 2.22, 2.35]
scaled_means = [3.12, 3.28, 2.86]

# Plotting
fig, ax = plt.subplots(figsize=(8, 6))

bar_width = 0.35
index = range(len(datasets))

bar1 = ax.bar(index, overall_means, bar_width, label='Overall Mean')
bar2 = ax.bar([i + bar_width for i in index], scaled_means, bar_width, label='Scaled Mean (0-5)')

ax.set_xlabel('Datasets')
ax.set_ylabel('Mean')
ax.set_title('Overall Mean and Scaled Mean (0-5) for Different Datasets')
ax.set_xticks([i + bar_width / 2 for i in index])
ax.set_xticklabels(datasets)
ax.legend()

plt.tight_layout()
plt.show()

datasets = ['KTEL', 'OSE', 'LIMANI']
evaluation_means = [62.4, 65.6, 57.2]

# Plotting
fig, ax = plt.subplots(figsize=(8, 6))

index = range(len(datasets))

bars = ax.bar(index, evaluation_means, color='skyblue')

ax.set_xlabel('Datasets')
ax.set_ylabel('Overall Evaluation of Transport Mean (%)')
ax.set_title('Overall Evaluation of Transport Mean for Different Datasets')
ax.set_xticks(index)
ax.set_xticklabels(datasets)

# Add percentage labels on top of each bar
for bar in bars:
    height = bar.get_height()
    ax.annotate('{}'.format(height),
                xy=(bar.get_x() + bar.get_width() / 2, height),
                xytext=(0, 3),  # 3 points vertical offset
                textcoords="offset points",
                ha='center', va='bottom')

plt.tight_layout()
plt.show()